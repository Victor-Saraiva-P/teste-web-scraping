![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![BeautifulSoup](https://img.shields.io/badge/BeautifulSoup-ffffff?style=for-the-badge&logo=python&logoColor=black)
![Requests](https://img.shields.io/badge/Requests-20232a?style=for-the-badge&logo=python&logoColor=white)
![Zipfile](https://img.shields.io/badge/Zipfile-BDBDBD?style=for-the-badge&logo=python&logoColor=black)

## Por que escolhi Python
Escolhi Python por ser mais simples e direto para tarefas de web scraping. Com poucas linhas, consigo acessar p√°ginas, fazer downloads e compactar arquivos. Java funcionaria tamb√©m, mas exigiria mais c√≥digo e configura√ß√£o para algo que o Python resolve de forma mais √°gil.
# Teste de Web Scraping

Este projeto tem como objetivo realizar o web scraping do site da ANS para a atualiza√ß√£o do rol de procedimentos, conforme desafio proposto para a vaga de est√°gio. O script acessa o site oficial, extrai os links dos Anexos I e II (em formato PDF), realiza o download dos arquivos e os compacta em um √∫nico arquivo (ZIP). O desenvolvimento segue as boas pr√°ticas de scraping, garantindo uma execu√ß√£o √©tica e eficiente, com tratamento de erros, controle de requisi√ß√µes e uso adequado de headers.
## Funcionalidades

- **Acesso ao Site:** Conecta-se ao site da ANS para extra√ß√£o dos dados.
- **Extra√ß√£o dos Links:** Identifica e captura os links dos PDFs dos Anexos I e II.
- **Download dos Arquivos:** Efetua o download dos arquivos PDF com controle de requisi√ß√µes e delays para evitar sobrecarga no servidor.
- **Compacta√ß√£o:** Agrupa os arquivos baixados em um √∫nico arquivo compactado (formato ZIP).
- **Tratamento de Erros:** Implementa tratamento de exce√ß√µes para garantir a robustez do scraper.
- **Logs Informativos:** Registra as etapas do processo para facilitar a monitora√ß√£o e depura√ß√£o.

## Stack Utilizada

- **Linguagem:** Python 3.x
- **Bibliotecas:**
  - `requests` ‚Äì Para realizar as requisi√ß√µes HTTP.
  - `BeautifulSoup` (ou `lxml`) ‚Äì Para parse e extra√ß√£o dos dados do HTML.
  - `zipfile` ‚Äì Para compacta√ß√£o dos arquivos.
  - `time` ‚Äì Para implementar delays entre as requisi√ß√µes.
- **Outras Ferramentas (opcionais):**
  - `Selenium` ‚Äì Caso seja necess√°rio interagir com p√°ginas din√¢micas (n√£o utilizado neste teste, mas citado como boa pr√°tica).

## Rodando Localmente

1. **Clone o Reposit√≥rio:**

   ```bash
   git clone https://github.com/seu-usuario/nome-do-repositorio.git
   cd nome-do-repositorio
   ```

2. **Crie um Ambiente Virtual e Instale as Depend√™ncias:**

   ```bash
   python3 -m venv venv
   source venv/bin/activate  # No Windows use: venv\Scripts\activate
   pip install -r requirements.txt
   ```

3. **Execute o Script:**

   ```bash
   python scraper.py
   ```

4. **Verifique os Resultados:**

   - Os arquivos PDF ser√£o baixados para o diret√≥rio definido.
   - O arquivo compactado (ZIP) com os anexos estar√° dispon√≠vel na pasta de sa√≠da.
   - Consulte os logs para acompanhar o andamento do processo.
   

## üë®‚Äçüíª Autor

Desenvolvido por **[Victor Saraiva](https://github.com/Victor-Saraiva-P)**
